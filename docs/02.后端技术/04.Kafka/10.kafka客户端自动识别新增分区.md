---
title: kafka客户端自动识别新增分区
date: 2024-08-06 23:06:24
permalink: /pages/fd37b0/
categories:
  - 后端技术
  - Kafka
  - Go
tags:
  - Kafka
  - Go
author: 
  name: erlangtui
  link: https://github.com/erlangtui
---

## 一、背景

广告曝光日志会通过 filebeat 写入 Kafka，下游服务消费 Kafka 获取日志信息并进行后续处理。由于最近巴黎奥运会热点事件频发，经常短时间内流量急剧暴涨，Kafka集群中心部分机器达到性能瓶颈，导致这些机器上的分区出现了消费堆积（写入也有问题），影响下游服务，Kafka 同学通过扩展对应 topic 的分区数量解决该问题。

Kafka 客户端消费服务是基于 go 语言编写的，使用的是 sarama-cluster 库，当分区数量增加时，没有自动识别出来，此时如果没有手动重启客户端触发 rebalance，则无法消费到新的分区导致消息丢失，影响后续业务。

## 二、go 常用的 Kafka 库
<!-- 
**Sarama** 和 **Sarama-cluster** 都是用于 Go 语言编写的 Apache Kafka 客户端库，它们提供了与 Kafka 集群进行通信的丰富功能和便捷方法。下面我会分别介绍它们的特点和用途：

### Sarama

**Sarama** 是一个纯粹的 Kafka 客户端库，它提供了与 Kafka 生产者和消费者进行交互的基本功能。主要特点包括：

1. **简单易用的 API**：Sarama 提供了简洁的 API，使得在 Go 语言中轻松地实现 Kafka 生产者和消费者。
   
2. **支持多版本 Kafka**：Sarama 支持 Kafka 0.8.2及以上版本，并针对不同的 Kafka 版本提供了相应的功能支持。

3. **高性能**：设计上优化了性能，尽可能地减少了与 Kafka 服务器之间的通信开销。

4. **灵活的配置选项**：可以配置多个参数，如连接超时、批量发送消息、消息压缩等，以满足不同场景下的需求。

5. **异步处理**：支持异步发送消息和异步处理接收到的消息，以提高吞吐量和响应性能。

Sarama 适合那些需要直接与 Kafka 交互，并且希望对底层细节有更多控制的应用程序。

### Sarama-cluster

**Sarama-cluster** 是基于 Sarama 构建的扩展库，专门用于简化基于 Kafka 集群的消费者组管理。其主要特点包括：

1. **消费者组管理**：Sarama-cluster 提供了更高级的消费者组管理功能，包括动态重新平衡、消费者偏移量的管理等。

2. **消费者健康监控**：能够监控消费者的健康状态，并支持自动故障转移和恢复。

3. **集群感知**：可以识别 Kafka 集群的所有 broker 节点，并自动在它们之间进行负载均衡。

4. **Offset 管理**：提供了管理消费者组偏移量的功能，确保消费者能够从上次停止的地方继续消费。

5. **动态重新平衡**：在消费者加入或退出时，能够自动调整分配给每个消费者的分区，以确保负载均衡。

Sarama-cluster 适合那些需要在多个消费者之间进行协调和负载均衡的应用程序，特别是大规模和高可用性的 Kafka 消费者。

### 总结

- **Sarama** 是一个基础的 Kafka 客户端库，适合简单的生产者和消费者实现。
- **Sarama-cluster** 在 Sarama 的基础上提供了更高级的消费者组管理功能，适合需要管理多个消费者实例的复杂应用场景。

根据你的具体需求和项目规模，选择适合的库可以有效地简化开发工作并提升系统的稳定性和性能。
 -->


## 三、sarama 
### 1，官方地址

 [「sarama官方地址」](https://pkg.go.dev/github.com/IBM/sarama)，[「kafka协议地址」](https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol)

### 2，简单介绍
Package sarama 是一个纯 Go 客户端库，用于处理 0.8 及更高版本 Apache Kafka。它包括一个高级API，用于轻松地生产和消费消息，以及一个低级API，用于在高级API不足时控制线路上的字节。

若要生成消息，可以使用 `AsyncProducer` 或 `SyncProducer`。`AsyncProducer` 接受管道上的消息 并尽可能高效地在后台异步生成它们,在大多数情况下，它是首选。`SyncProducer` 提供了一种方法，该方法将阻塞，直到 Kafka 确认生成的消息。但它通常效率较低，并且实际的可靠性依赖于“Producer.RequiredAcks”的配置值，在某些配置中，消息由 SyncProducer 有时仍可能丢失。

要消费消息，可以使用 Consumer 或 Consumer-Group API。对于较低级别的需求，Broker 和 Request/Response 对象允许对每个连接进行精确控制，并通过线路发送的消息，客户端提供更高级别的元数据管理，该管理在生产者和消费者之间共享。

### 3，客户端示例代码
* 此处选用的 sarama 包版本是 v1.38.1，更高版本与我们的服务端版本不兼容，无法正常消费消息；

```go
package main

// SIGUSR1 toggle the pause/resume consumption
import (
	"context"
	"errors"
	"log"
	"os"
	"os/signal"
	"sync"
	"syscall"

	"github.com/Shopify/sarama"
)

// Sarama configuration options
var (
	brokers      = []string{"yz-cen048.kafka.data.cn:9120", "bx-mq002.kafka.data.cn:9120"}
	group        = "go_part_auto_discover_test1_sarama"
	topics       = []string{"go_part_auto_discover_test1"}
	SASLUser     = "adEngine"
	SASLPassword = "bc5007d7935"
)

func main() {
	// v1.38.1 包版本，更高版本与服务端版本不兼容
	log.Println("Starting a new Sarama consumer")

	sarama.Logger = log.New(os.Stdout, "[sarama] ", log.LstdFlags)
	config := sarama.NewConfig()
	config.Version = sarama.V0_10_2_1 // 配置版本
	config.Consumer.Offsets.Initial = sarama.OffsetNewest // 配置消费起始位移
	config.Net.SASL.Enable = true
	config.Net.SASL.Mechanism = sarama.SASLTypePlaintext
	config.Net.SASL.User = SASLUser
	config.Net.SASL.Password = SASLPassword
	// config.Consumer.Return.Errors = true

	consumer := Consumer{
		ready: make(chan bool),
	}

	ctx, cancel := context.WithCancel(context.Background())
	client, err := sarama.NewConsumerGroup(brokers, group, config)
	if err != nil {
		log.Printf("Error creating consumer group client: %v", err)
		return
	}

	wg := &sync.WaitGroup{}
	wg.Add(1)
	go func() {
		defer wg.Done()
		for {
			if err := client.Consume(ctx, topics, &consumer); err != nil {
				if errors.Is(err, sarama.ErrClosedConsumerGroup) {
					return
				}
				log.Panicf("Error from consumer: %v", err)
			}
			// check if context was cancelled, signaling that the consumer should stop
			if ctx.Err() != nil {
				return
			}
			consumer.ready = make(chan bool)
		}
	}()

	<-consumer.ready // Await till the consumer has been set up
	log.Println("Sarama consumer up and running!...")

	sigterm := make(chan os.Signal, 1)
	signal.Notify(sigterm, syscall.SIGINT, syscall.SIGTERM)

	keepRunning := true
	for keepRunning {
		select {
		case <-ctx.Done():
			log.Println("terminating: context cancelled")
			keepRunning = false
		case <-sigterm:
			log.Println("terminating: via signal")
			keepRunning = false
		}
	}
	cancel()
	wg.Wait()
	if err = client.Close(); err != nil {
		log.Panicf("Error closing client: %v", err)
	}
}

// Consumer represents a Sarama consumer group consumer
type Consumer struct {
	ready chan bool
}

// Setup is run at the beginning of a new session, before ConsumeClaim
func (consumer *Consumer) Setup(sarama.ConsumerGroupSession) error {
	// Mark the consumer as ready
	close(consumer.ready)
	return nil
}

// Cleanup is run at the end of a session, once all ConsumeClaim goroutines have exited
func (consumer *Consumer) Cleanup(sarama.ConsumerGroupSession) error {
	return nil
}

// ConsumeClaim must start a consumer loop of ConsumerGroupClaim's Messages().
// Once the Messages() channel is closed, the Handler must finish its processing
// loop and exit.
func (consumer *Consumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	for {
		select {
		case message, ok := <-claim.Messages():
			if !ok {
				log.Printf("message channel was closed")
				return nil
			}
			log.Printf("topic: %s, group: %s, partition: %d, msg: %s", message.Topic, group, message.Partition, string(message.Value))
			session.MarkMessage(message, "")
		case <-session.Context().Done():
			return nil
		}
	}
}
```

## 四、sarama-cluster

### 1，官方地址
 [「sarama官方地址」]()，[「kafka协议地址」]()

### 2，简单介绍
### 3，客户端示例代码
```go
package main

import (
	"fmt"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/Shopify/sarama"
	cluster "github.com/bsm/sarama-cluster"
	"go.uber.org/zap"
)

var (
	brokers      = []string{"yz-cen048.kafka.data.sina.com.cn:9120", "bx-mq002.kafka.data.sina.com.cn:9120", "yz-cen063.kafka.data.sina.com.cn:9120", "bx-mq001.kafka.data.sina.com.cn:9120", "yz-cen049.kafka.data.sina.com.cn:9120", "yz-cen070.kafka.data.sina.com.cn:9120"}
	group        = "go_part_auto_discover_test1_sarama"
	topics       = []string{"go_part_auto_discover_test1"}
	SASLUser     = "adEngine"
	SASLPassword = "bc5007d7935305b583fab9c93949dc82"
)

func main() {

	sarama.Logger = log.New(os.Stdout, "[sarama-cluster] ", log.LstdFlags)
	InitConsumer()
	// 响应kill -15和ctrl-c信号
	q := make(chan os.Signal, 1)
	signal.Notify(q, syscall.SIGINT, syscall.SIGTERM)
	<-q
}

func newConsumer() (*cluster.Consumer, error) {
	config := cluster.NewConfig()
	config.Net.SASL.Enable = true
	config.Net.SASL.User = SASLUser
	config.Net.SASL.Password = SASLPassword
	config.Consumer.Return.Errors = true
	config.Group.Return.Notifications = true
	config.Consumer.MaxWaitTime = 800 * time.Millisecond
	config.Consumer.Offsets.CommitInterval = time.Second
	config.Consumer.Offsets.Initial = sarama.OffsetOldest
	config.Metadata.RefreshFrequency = time.Minute
	config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRoundRobin
	config.Version = sarama.V0_10_2_1

	return cluster.NewConsumer(brokers, group, topics, config)
}

// InitConsumer kafka消费者, 不断地从kafka中消费数据, 写入管道中供工作者消费
func InitConsumer() {
	consumer, err := newConsumer()
	if err != nil {
		panic(err)
	}

	sarama.Logger.Printf("⇨ create kafka consumer finish and start consume, topic : %s, group : %s\n", topics[0], group)

	go consume(topics[0], group, consumer)
}

func consume(topic, group string, consumer *cluster.Consumer) {

	go func(topic string, consumer *cluster.Consumer) {
		for {
			msg, ok := <-consumer.Messages()
			if ok {
				consumer.MarkOffset(msg, "")
				sarama.Logger.Printf("input message, topic: %s, group: %s, partition: %d, offset: %d, msg: %s\n", msg.Topic, group, msg.Partition, msg.Offset, string(msg.Value))
			}
		}
	}(topic, consumer)

	// 和上面分成2个协程是有好处的：如果不分开，MessageChan写的时候堵塞住了，下面所有信息都打印不出来
	go func(topic string, consumer *cluster.Consumer) {
		// 协程的心跳
		heartbeat := time.Tick(5 * time.Second)
		for {
			select {
			case <-heartbeat:
				// 如果读取kafka堵塞了, 则info日志里全是心跳日志
				sarama.Logger.Println("consumer alive", zap.String("topic", topic))

			case err, ok := <-consumer.Errors():
				if ok {
					sarama.Logger.Println(err.Error(), zap.String("topic", topic))
				}

			case ntf, ok := <-consumer.Notifications():
				if ok {
					sarama.Logger.Println(fmt.Sprintf("%+v", ntf), zap.String("topic", topic))
				}
			}
		}

	}(topic, consumer)

	// 响应kill -15和ctrl-c信号
	q := make(chan os.Signal, 1)
	signal.Notify(q, syscall.SIGINT, syscall.SIGTERM)
	<-q

	consumer.Close()
	sarama.Logger.Println("consumer quit finish", zap.String("topic", topic))
}
```
## 五、kafka-go
### 1，官方地址
 [「sarama官方地址」]()，[「kafka协议地址」]()

### 2，简单介绍
### 3，客户端示例代码
```go
package main

import (
	"context"
	"fmt"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/segmentio/kafka-go"
	"github.com/segmentio/kafka-go/sasl/plain"
)

var (
	brokers      = []string{"yz-cen048.kafka.data.sina.com.cn:9120", "bx-mq002.kafka.data.sina.com.cn:9120", "yz-cen063.kafka.data.sina.com.cn:9120", "bx-mq001.kafka.data.sina.com.cn:9120", "yz-cen049.kafka.data.sina.com.cn:9120", "yz-cen070.kafka.data.sina.com.cn:9120"}
	group        = "go_part_auto_discover_test1_group"
	topic        = "go_part_auto_discover_test1"
	SASLUser     = "adEngine"
	SASLPassword = "bc5007d7935305b583fab9c93949dc82"
)

func main() {
	InitConsumer()
	q := make(chan os.Signal, 1)
	signal.Notify(q, syscall.SIGINT, syscall.SIGTERM)
	<-q
}

func newConsumer() *kafka.Reader {
	s := plain.Mechanism{
		Username: SASLUser,
		Password: SASLPassword,
	}
	r := kafka.NewReader(kafka.ReaderConfig{
		Brokers: brokers,
		Topic:   topic,
		Dialer: &kafka.Dialer{
			Timeout:       10 * time.Second,
			DualStack:     true,
			SASLMechanism: s,
		},
		QueueCapacity:  2000,
		CommitInterval: time.Second,
		StartOffset:    kafka.LastOffset,
		MaxBytes:       10e6, // 10MB
		GroupID:        group,
	})
	return r
}

func InitConsumer() {
	consumer := newConsumer()

	fmt.Printf("⇨ create kafka consumer finish and start consume, topic : %s, group : %s\n", topic, group)

	go consume(group, consumer)

}

func consume(group string, r *kafka.Reader) {
	defer r.Close()
	for {
		msg, err := r.ReadMessage(context.Background())
		if err != nil {
			fmt.Printf("consume error: %v\v", err)
			continue
		}
		fmt.Printf("input message, topic: %s, group: %s, partition: %d, offset: %d, msg: %s\n", msg.Topic, group, msg.Partition, msg.Offset, string(msg.Value))
	}
}
```
## 六、confluent-kafka-go
### 1，官方地址
 [「sarama官方地址」]()，[「kafka协议地址」]()

### 2，简单介绍
### 3，客户端示例代码
```go
package main

import (
	"fmt"
	"os"
	"os/signal"
	"strings"
	"syscall"
	"time"

	"github.com/confluentinc/confluent-kafka-go/v2/kafka"
)

var (
	brokers      = []string{"yz-cen048.kafka.data.sina.com.cn:9120", "bx-mq002.kafka.data.sina.com.cn:9120", "yz-cen063.kafka.data.sina.com.cn:9120", "bx-mq001.kafka.data.sina.com.cn:9120", "yz-cen049.kafka.data.sina.com.cn:9120", "yz-cen070.kafka.data.sina.com.cn:9120"}
	group        = "go_part_auto_discover_test1_confluent"
	topic        = "go_part_auto_discover_test1"
	SASLUser     = "adEngine"
	SASLPassword = "bc5007d7935305b583fab9c93949dc82"
)

func main() {
	// v2.2.0 包版本，高版本会要求 go 1.21 以上
	InitConsumer()
	// 响应kill -15和ctrl-c信号
	q := make(chan os.Signal, 1)
	signal.Notify(q, syscall.SIGINT, syscall.SIGTERM)
	<-q
}

func newConsumer() *kafka.Consumer {
	broker := strings.Join(brokers, ",")
	cli, err := kafka.NewConsumer(&kafka.ConfigMap{
		"bootstrap.servers": broker,
		"group.id":          group,
		"security.protocol": "SASL_PLAINTEXT",
		"sasl.mechanisms":   "PLAIN",
		"sasl.username":     SASLUser,
		"sasl.password":     SASLPassword,
		"auto.offset.reset": "earliest",
	})
	if err != nil {
		panic(err)
	}

	if err = cli.Subscribe(topic, nil); err != nil {
		panic(err)
	}
	return cli
}

func InitConsumer() {
	consumer := newConsumer()
	fmt.Printf("⇨ create kafka consumer finish and start consume, topic : %s, group : %s\n", topic, group)

	go consume(group, consumer)

}

func consume(group string, c *kafka.Consumer) {
	defer c.Close()
	for {
		msg, err := c.ReadMessage(time.Second)
		if err == nil {
			fmt.Printf("input message: topic: %s, group: %s, partition: %d, offset: %d, msg: %s\n", *msg.TopicPartition.Topic, group, msg.TopicPartition.Partition, int64(msg.TopicPartition.Offset), string(msg.Value))
			continue
		}
		if !err.(kafka.Error).IsTimeout() {
			// The client will automatically try to recover from all errors.
			// Timeout is not considered an error because it is raised by
			// ReadMessage in absence of messages.
			fmt.Printf("Consumer error: %v (%v)\n", err, msg)
		}
	}
}
```
## 七、总结

kafka 的 go 客户端常用的几个库分别是 sarama、sarama-cluster、kafka-go、confluent-kafka-go。
另外有一个小问题，即使能够自动识别新分区触发 rebalance，如果客户端的消费起始位移配置的是从最新处开始消费，当客户端 rebalance 完毕开始从新分区消费消息时，是从分区的最新处开始消费，客户端无法消费在新分区开始接收消息到客户端开始从新分区消费消息这段时间内的消息，导致消息丢失。