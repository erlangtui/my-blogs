---
title: kafka客户端自动识别新增分区
date: 2024-08-06 23:06:24
permalink: /pages/fd37b0/
categories:
  - 后端技术
  - Kafka
  - Go
tags:
  - Kafka
  - Go
author: 
  name: erlangtui
  link: https://github.com/erlangtui
---

## 一、背景

广告曝光日志会通过 filebeat 写入 Kafka，下游服务消费 Kafka 获取日志信息并进行后续处理。由于最近巴黎奥运会热点事件频发，经常短时间内流量急剧暴涨，Kafka集群中心部分机器达到性能瓶颈，导致这些机器上的分区出现了消费堆积（写入也有问题），影响下游服务，Kafka 同学通过扩展对应 topic 的分区数量解决该问题。

Kafka 客户端消费服务是基于 go 语言编写的，使用的是 sarama-cluster 库，当分区数量增加时，没有自动识别出来，此时如果没有手动重启客户端触发 rebalance，则无法消费到新的分区导致消息丢失，影响后续业务。

另外，即使能够自动识别新分区触发 rebalance，如果客户端的消费起始位移配置的是从最新处开始消费，当客户端 rebalance 完毕开始从新分区消费消息时，是从分区的最新处开始消费，客户端无法消费在新分区开始接收消息到客户端开始从新分区消费消息这段时间内的消息，导致消息丢失。

## 二、go 常用的 Kafka 库

## 三、sarama 
### 1，官方地址

 [「sarama官方地址」](https://pkg.go.dev/github.com/IBM/sarama)，[「kafka协议地址」](https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol)

### 2，简单介绍
Package sarama 是一个纯 Go 客户端库，用于处理 0.8 及更高版本 Apache Kafka。它包括一个高级API，用于轻松地生产和消费消息，以及一个低级API，用于在高级API不足时控制线路上的字节。

若要生成消息，可以使用 `AsyncProducer` 或 `SyncProducer`。`AsyncProducer` 接受管道上的消息 并尽可能高效地在后台异步生成它们,在大多数情况下，它是首选。`SyncProducer` 提供了一种方法，该方法将阻塞，直到 Kafka 确认生成的消息。但它通常效率较低，并且实际的可靠性依赖于“Producer.RequiredAcks”的配置值，在某些配置中，消息由 SyncProducer 有时仍可能丢失。

要消费消息，可以使用 Consumer 或 Consumer-Group API。对于较低级别的需求，Broker 和 Request/Response 对象允许对每个连接进行精确控制，并通过线路发送的消息，客户端提供更高级别的元数据管理，该管理在生产者和消费者之间共享。

### 3，客户端消费

## 四、sarama-cluster

## 五、kafka-go

## 六、confluent-kafka-go

## 七、总结

kafka 的 go 客户端常用的几个库分别是 sarama、sarama-cluster、kafka-go、confluent-kafka-go。
